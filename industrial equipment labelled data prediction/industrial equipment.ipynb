{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Image Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Width=128\n",
    "Image_Height=128\n",
    "Image_Size=(Image_Width,Image_Height)\n",
    "Image_Channels=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path of the training images data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "\n",
    "dataset_dir = r\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "filenames = os.listdir(dataset_dir)\n",
    "\n",
    "categories = []\n",
    "for f_name in filenames:\n",
    "    category = f_name.split('.')[0]\n",
    "    # Assuming your defective images are labeled as 'defective' and non-defective as 'non_defective'\n",
    "    if category == 'defective':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Convolutional Neural Network (CNN) Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(Image_Width, Image_Height, Image_Channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Callbacks for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'non-defective' and 'defective' respectively\n",
    "df[\"category\"] = df[\"category\"].replace({0: 'non-defective', 1: 'defective'})\n",
    "\n",
    "# Split the DataFrame into training and validation sets\n",
    "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "\n",
    "# Reset the index of the training and validation DataFrames\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "\n",
    "# Get the total number of samples in the training and validation sets\n",
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "\n",
    "# Define the batch size for training\n",
    "batch_size = 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation and Image Data Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide the train data images path and test data images path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = r\"\"\n",
    "\n",
    "test_data = r\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the list of filenames in the test directory\n",
    "test_filenames = os.listdir(test_data)\n",
    "\n",
    "# Create a DataFrame for the test data\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Training data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    \n",
    "    \n",
    "    # train data\n",
    "    train_data,  \n",
    "    \n",
    "    \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=Image_Size,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Validation data generator (only rescaling)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df,\n",
    "    \n",
    "    \n",
    "    # train data \n",
    "    train_data,  \n",
    "    \n",
    "    \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=Image_Size,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Test data generator (similar to validation, no augmentation, only rescaling)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    \n",
    "#   test data \n",
    "    test_data,  \n",
    "    \n",
    "    \n",
    "    x_col='filename',\n",
    "    target_size=Image_Size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,  # Set class_mode to None since the DataFrame does not contain labels\n",
    "    shuffle=False  # Set shuffle to False to ensure that predictions are in the same order as filenames\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Recreate the optimizer\n",
    "optimizer = RMSprop()\n",
    "\n",
    "# Compile the model with the new optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Resume training\n",
    "epochs = 1\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model1_industrial_equipment_labelled_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Sample Images from the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "sample_test = df.head(18)\n",
    "plt.figure(figsize=(12, 24))\n",
    "for index, row in sample_test.iterrows():\n",
    "    filename = row['filename']\n",
    "    # Assuming 'category' is the column containing class labels\n",
    "    category = row['category']\n",
    "    \n",
    "    # Correcting the file path with single forward slashes\n",
    "    img_path = r\"\" + filename\n",
    "    \n",
    "    \n",
    "    img = load_img(img_path, target_size=Image_Size)\n",
    "    plt.subplot(6, 3, index+1)\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Class Label for a Single Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model :: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasting 1 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the image path there\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = r\"\"          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the image                    \n",
    "\n",
    "im = Image.open(image)\n",
    "im = im.resize(Image_Size)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "im = np.array(im)\n",
    "im = im / 255\n",
    "\n",
    "# Predict the class probabilities\n",
    "pred_probs = model.predict(im)[0]\n",
    "\n",
    "# Extract the class with the highest probability\n",
    "pred_class = np.argmax(pred_probs)\n",
    "\n",
    "\n",
    "results = {0: 'non-defective', 1: 'defective'}  \n",
    "pred_label = results[pred_class]\n",
    "\n",
    "print(\"Predicted class:\", pred_class)\n",
    "print(\"Predicted label:\", pred_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI for Defective Equipment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasting 2 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the saved model path : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = r\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button\n",
    "from PIL import ImageTk, Image\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the pre-trained model\n",
    "\n",
    "\n",
    "model = load_model(modelpath) \n",
    "\n",
    "# Define the class labels\n",
    "classes = {0: 'non-defective', 1: 'defective'}\n",
    "\n",
    "# Initialize GUI\n",
    "top = tk.Tk()\n",
    "top.geometry('800x600')\n",
    "top.title('Defective Equipment Classification')\n",
    "top.configure(background='#CDCDCD')\n",
    "\n",
    "# Define the label for displaying the prediction\n",
    "label = Label(top, background='#CDCDCD', font=('arial', 15, 'bold'))\n",
    "sign_image = Label(top)\n",
    "\n",
    "# Function to classify the uploaded image\n",
    "def classify(file_path):\n",
    "    try:\n",
    "        # Load and preprocess the image\n",
    "        image = Image.open(file_path)\n",
    "        image = image.resize((128, 128))\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = np.array(image)\n",
    "        image = image / 255\n",
    "\n",
    "        # Predict the class probabilities\n",
    "        pred_probs = model.predict(image)[0]\n",
    "\n",
    "        # Extract the class with the highest probability\n",
    "        pred_class = np.argmax(pred_probs)\n",
    "\n",
    "        # Map the class index to its corresponding label\n",
    "        pred_label = classes[pred_class]\n",
    "\n",
    "        # Update the label with the predicted class\n",
    "        label.configure(foreground='#011638', text=pred_label)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred during classification:\", e)\n",
    "        label.configure(foreground='#011638', text=\"An error occurred during classification.\")\n",
    "\n",
    "# Function to display the \"Classify Image\" button\n",
    "def show_classify_button(file_path):\n",
    "    classify_b = Button(top, text=\"Classify Image\", command=lambda: classify(file_path), padx=10, pady=5)\n",
    "    classify_b.configure(background='#364156', foreground='white', font=('arial', 10, 'bold'))\n",
    "    classify_b.place(relx=0.79, rely=0.46)\n",
    "\n",
    "# Function to upload an image\n",
    "def upload_image():\n",
    "    try:\n",
    "        file_path = filedialog.askopenfilename()\n",
    "        uploaded = Image.open(file_path)\n",
    "        uploaded.thumbnail(((top.winfo_width() / 2.25), (top.winfo_height() / 2.25)))\n",
    "        im = ImageTk.PhotoImage(uploaded)\n",
    "        sign_image.configure(image=im)\n",
    "        sign_image.image = im\n",
    "        label.configure(text='')\n",
    "        show_classify_button(file_path)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred during image upload:\", e)\n",
    "\n",
    "# Button to upload an image\n",
    "upload = Button(top, text=\"Upload an image\", command=upload_image, padx=10, pady=5)\n",
    "upload.configure(background='#364156', foreground='white', font=('arial', 10, 'bold'))\n",
    "upload.pack(side=tk.BOTTOM, pady=50)\n",
    "\n",
    "# Label to display the uploaded image\n",
    "sign_image.pack(side=tk.BOTTOM, expand=True)\n",
    "\n",
    "# Label to display the classification result\n",
    "label.pack(side=tk.BOTTOM, expand=True)\n",
    "\n",
    "# Heading label\n",
    "heading = Label(top, text=\"Defective Equipment Classification\", pady=20, font=('arial', 20, 'bold'))\n",
    "heading.configure(background='#CDCDCD', foreground='#364156')\n",
    "heading.pack()\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "top.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
